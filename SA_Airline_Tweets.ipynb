{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Airline Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
      "Requirement already satisfied: torch_nightly in /home/kat/anaconda3/lib/python3.7/site-packages (1.2.0.dev20190805+cu92)\n",
      "Requirement already satisfied: fastai in /home/kat/anaconda3/lib/python3.7/site-packages (1.0.61)\n",
      "Requirement already satisfied: matplotlib in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: torchvision in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (0.6.1)\n",
      "Requirement already satisfied: scipy in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (4.9.1)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (0.2.3)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied: pandas in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (1.18.5)\n",
      "Requirement already satisfied: bottleneck in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (1.3.2)\n",
      "Requirement already satisfied: packaging in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (20.4)\n",
      "Requirement already satisfied: numexpr in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (2.7.1)\n",
      "Requirement already satisfied: Pillow in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (7.1.2)\n",
      "Requirement already satisfied: requests in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (2.24.0)\n",
      "Requirement already satisfied: pyyaml in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (5.3.1)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (2.3.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from fastai) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kat/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (1.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->fastai) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from pandas->fastai) (2020.1)\n",
      "Requirement already satisfied: six in /home/kat/anaconda3/lib/python3.7/site-packages (from packaging->fastai) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from requests->fastai) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kat/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kat/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2020.6.20)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (47.3.1.post20200622)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.47.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/kat/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
      "Requirement already satisfied: future in /home/kat/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->fastai) (0.18.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/kat/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kat/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.1.0)\n",
      "Requirement already satisfied: nltk in /home/kat/anaconda3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /home/kat/anaconda3/lib/python3.7/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in /home/kat/anaconda3/lib/python3.7/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in /home/kat/anaconda3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/kat/anaconda3/lib/python3.7/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: sklearn in /home/kat/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/kat/anaconda3/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/kat/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/kat/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kat/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/kat/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
    "!pip install fastai\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Airline Sentiment Data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'sentiment':dataset.airline_sentiment, 'tweet':dataset.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                              tweet\n",
       "0   neutral                @VirginAmerica What @dhepburn said.\n",
       "1  positive  @VirginAmerica plus you've added commercials t...\n",
       "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3  negative  @VirginAmerica it's really aggressive to blast...\n",
       "4  negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "\t#replace anything that isn't a letter into a space\n",
    "    text = re.sub('[^a-zA-Z]', ' ', df['tweet'][i])\n",
    "    #make everything lowercase\n",
    "    text = text.lower()\n",
    "    #split into words\n",
    "    text = text.split()\n",
    "    #stopwords are irrelevant words (i.e. the)\n",
    "    text = [word for word in text if not word in set(stopwords.words('english'))]\n",
    "    #rejoin words by spaces\n",
    "    df['tweet'][i] = ' '.join(text)\n",
    "    corpus.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8784, 2), (5856, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(df, stratify = df['sentiment'], test_size = 0.4, random_state = 12)\n",
    "df_trn.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Language Model Data and Classifier Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
    "\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.510352</td>\n",
       "      <td>6.321576</td>\n",
       "      <td>0.098899</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.023198</td>\n",
       "      <td>5.579774</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a tweet about yes painful republican makes lax thought explanation accommodations clearly xxbos'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"This is a tweet about\", n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (8784 items)\n",
       "x: TextList\n",
       "xxbos americanair ok one help bag lost honeymoon months ago responsible professional,xxbos united xxwrep 5 lt shoddy customer service use xxunk xxunk,xxbos jetblue fleet fleek http co xxunk xxunk xxunk,xxbos southwestair xxunk,xxbos americanair tired sitting delayed computer\n",
       "y: CategoryList\n",
       "negative,negative,neutral,neutral,negative\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (5856 items)\n",
       "x: TextList\n",
       "xxbos americanair filled whole form receiving poor poor response direct email address reply,xxbos usairways kids anxious husband sit current xxunk warning seats changed,xxbos southwestair opening flights beyond august th,xxbos southwestair fan imagine dragons since fave band destinationdragons bday get tix,xxbos jetblue new ceo seeks right balance please passengers wall xxunk daily xxunk http co xxunk xxunk\n",
       "y: CategoryList\n",
       "negative,negative,neutral,neutral,neutral\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(4464, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(4464, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f51b4f40050>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(4464, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(4464, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos southwestair needs make whole used tkt back n phx due rude sna agent jacquie plitt flew usairways cabo http co xxunk p</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos southwestair could maybe hook xxunk imagine dragon tickets tonight she s hug xxrep 5 e fan amp would really love go</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos americanair file loc xxunk bag airport since last nite scheduled get xxunk xxunk xxunk u shld b ashamed disgusted w u</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos usairways customer service dead last xxunk flts delayed cancelled flighted bags lost days last nt flt delayed cancelled flighted meal voucher</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos united ticket h biz trvl wifi missed xxunk flt next one h missed meeting food voucher hotel xxunk flt wifi hotel</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.771959</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.709870</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.731729</td>\n",
       "      <td>0.672766</td>\n",
       "      <td>0.712944</td>\n",
       "      <td>01:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.653900</td>\n",
       "      <td>0.607690</td>\n",
       "      <td>0.748975</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(0), tensor(0), tensor([0.8810, 0.0559, 0.0631]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Horrible service, will not fly again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3509</td>\n",
       "      <td>792</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>328</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>120</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1    2\n",
       "row_0                \n",
       "0      3509  792  334\n",
       "1        79  328   62\n",
       "2        83  120  549"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "preds, targets = learn.get_preds()\n",
    "\n",
    "predictions = np.argmax(preds, axis = 1)\n",
    "pd.crosstab(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ULMFiT</th>\n",
       "      <td>0.748975</td>\n",
       "      <td>0.728826</td>\n",
       "      <td>0.600446</td>\n",
       "      <td>0.625269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision    Recall  F1 Score\n",
       "ULMFiT  0.748975   0.728826  0.600446  0.625269"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "results = []\n",
    "results.append(\n",
    "    [accuracy_score(targets, predictions),\n",
    "     precision_score(targets, predictions, average = 'macro'),\n",
    "    recall_score(targets, predictions, average = 'macro'),\n",
    "    f1_score(targets, predictions, average = 'macro')]\n",
    ")\n",
    "resultsinDataFrame = pd.DataFrame(results, columns = ['Accuracy', 'Precision', 'Recall', 'F1 Score'], index = ['ULMFiT'])\n",
    "resultsinDataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
